{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4b6b3b",
   "metadata": {},
   "source": [
    "# State-of-the-Art Speech Recognition Model Comparison\n",
    "\n",
    "Comparing different state-of-the-art speech recognition models with a focus on Wav2Vec 2.0 as the baseline. We'll evaluate models on different aspects:\n",
    "\n",
    "1. Accuracy (Word Error Rate - WER) and (character Error Rate - CER)\n",
    "2. Processing Speed\n",
    "3. Memory Usage\n",
    "4. Language Support\n",
    "5. Resource Requirements\n",
    "\n",
    "Models to compare:\n",
    "1. Wav2Vec 2.0 (Base)\n",
    "2. Wav2Vec 2.0 (Large)\n",
    "3. Whisper (Small)\n",
    "4. XLSR-53 (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    Wav2Vec2ForCTC, \n",
    "    Wav2Vec2Processor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor\n",
    ")\n",
    "import transformers\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from jiwer import wer\n",
    "import warnings\n",
    "import subprocess\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def check_dependencies():\n",
    "    \"\"\"Verify all required packages are installed\"\"\"\n",
    "    try:\n",
    "        import google.protobuf\n",
    "        import sentencepiece\n",
    "        print(\"Required packages verified:\")\n",
    "        print(f\"protobuf {google.protobuf.__version__}\")\n",
    "        print(f\"torch {torch.__version__}\")\n",
    "        print(f\"torchaudio {torchaudio.__version__}\")\n",
    "        print(f\"ransformers {transformers.__version__}\")\n",
    "        \n",
    "        # Check FFmpeg\n",
    "        try:\n",
    "            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                ffmpeg_ver = result.stdout.split('\\n')[0]\n",
    "                print(f\"{ffmpeg_ver}\")\n",
    "            else:\n",
    "                print(\"FFmpeg check failed - make sure it's in PATH\")\n",
    "        except Exception as e:\n",
    "            print(f\"FFmpeg not found: {str(e)}\")\n",
    "            print(\"\\nTo fix, run in your terminal:\")\n",
    "            print(\"winget install Gyan.FFmpeg\")\n",
    "            raise\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(\"Missing required package:\", str(e))\n",
    "        print(\"\\nTo fix, run in your terminal:\")\n",
    "        print(\"pip install protobuf>=3.20.0 sentencepiece librosa\")\n",
    "        print(\"\\nThen restart the kernel.\")\n",
    "        raise\n",
    "\n",
    "# Memory optimization\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.set_num_threads(4)  # Limit CPU threads for laptop\n",
    "\n",
    "def print_system_info():\n",
    "    \"\"\"Print system information\"\"\"\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Available Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f}GB\")\n",
    "    print(f\"CPU Threads: {torch.get_num_threads()}\")\n",
    "    \n",
    "print(\"\\nSystem Information\")\n",
    "print_system_info()\n",
    "print(\"\\nPackage Check\")\n",
    "check_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "MODELS = {\n",
    "    \"wav2vec2-small\": {\n",
    "        \"name\": \"facebook/wav2vec2-base-100h\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"Smaller Wav2Vec2 (trained on 100h, faster)\"\n",
    "    },\n",
    "    \"wav2vec2-base\": {\n",
    "        \"name\": \"facebook/wav2vec2-base-960h\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"Base Wav2Vec2 (960h training)\"\n",
    "    },\n",
    "    \"whisper-small\": {\n",
    "        \"name\": \"openai/whisper-small\",\n",
    "        \"type\": \"whisper\",\n",
    "        \"description\": \"OpenAI Whisper (small, multilingual)\"\n",
    "    },\n",
    "    \"xlsr-english\": {\n",
    "        \"name\": \"facebook/wav2vec2-large-xlsr-53-english\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"XLSR-53 fine-tuned for English\"\n",
    "    },\n",
    "    \"xlsr-spanish\": {\n",
    "        \"name\": \"facebook/wav2vec2-large-xlsr-53-spanish\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"XLSR-53 fine-tuned for Spanish\"\n",
    "    },\n",
    "    \"xlsr-french\": {\n",
    "        \"name\": \"facebook/wav2vec2-large-xlsr-53-french\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"XLSR-53 fine-tuned for French\"\n",
    "    },\n",
    "    \"xlsr-hindi\": {\n",
    "        \"name\": \"facebook/wav2vec2-large-xlsr-53-hindi\",\n",
    "        \"type\": \"wav2vec2\",\n",
    "        \"description\": \"XLSR-53 fine-tuned for Hindi\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Available models:\")\n",
    "for name, info in MODELS.items():\n",
    "    print(f\"{name:<15} - {info['description']}\")\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model_config):\n",
    "        self.config = model_config\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        \n",
    "    def load(self):\n",
    "        \"\"\"Load model with memory optimization\"\"\"\n",
    "        print(f\"\\nLoading {self.config['name']}...\")\n",
    "        try:\n",
    "            if self.config[\"type\"] == \"wav2vec2\":\n",
    "                self.processor = Wav2Vec2Processor.from_pretrained(self.config[\"name\"])\n",
    "                self.model = Wav2Vec2ForCTC.from_pretrained(\n",
    "                    self.config[\"name\"],\n",
    "                    low_cpu_mem_usage=True\n",
    "                )\n",
    "            else:\n",
    "                # whisper\n",
    "                self.processor = WhisperProcessor.from_pretrained(self.config[\"name\"])\n",
    "                self.model = WhisperForConditionalGeneration.from_pretrained(\n",
    "                    self.config[\"name\"],\n",
    "                    low_cpu_mem_usage=True\n",
    "                )\n",
    "            self.model.eval()\n",
    "            print(f\"Loaded {self.config['name']}\")\n",
    "            return self\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {self.config['name']}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def transcribe(self, audio, sr):\n",
    "        \"\"\"Transcribe audio\"\"\"\n",
    "        if self.config[\"type\"] == \"wav2vec2\":\n",
    "            if audio.ndim > 1:\n",
    "                audio = audio.mean(axis=1)\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(inputs.input_values).logits\n",
    "            ids = torch.argmax(logits, dim=-1)\n",
    "            return self.processor.batch_decode(ids)[0]\n",
    "        else:  # whisper\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                generated_ids = self.model.generate(inputs.input_features)\n",
    "            return self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "    def unload(self):\n",
    "        \"\"\"Free memory\"\"\"\n",
    "        try:\n",
    "            del self.model\n",
    "            del self.processor\n",
    "            torch.cuda.empty_cache()\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            print(f\"Unloaded model and freed memory\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during unload: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test datasets\n",
    "def load_test_audio(audio_path, max_duration=30):\n",
    "    \"\"\"Load test audio file with duration limit\"\"\"\n",
    "    try:\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(audio_path, sr=16000, duration=max_duration)\n",
    "            print(f\"Loaded {audio_path} with librosa\")\n",
    "            return audio, sr\n",
    "        except Exception as e:\n",
    "            print(f\"Librosa load failed, trying soundfile: {str(e)}\")\n",
    "            \n",
    "        # Fallback to soundfile\n",
    "        audio, sr = sf.read(audio_path)\n",
    "        if len(audio) > sr * max_duration:\n",
    "            audio = audio[:sr * max_duration]\n",
    "            print(f\"Truncated {audio_path} to {max_duration}s\")\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio.T)\n",
    "        \n",
    "        # Resample to 16kHz if needed\n",
    "        if sr != 16000:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "            sr = 16000\n",
    "            print(f\"Resampled to {sr}Hz\")\n",
    "            \n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {audio_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Define test datasets\n",
    "TEST_FILES = {\n",
    "    \"english\": [\n",
    "        \"./data/test/eng1.wav\",\n",
    "        \"./data/test/eng2.wav\"\n",
    "    ],\n",
    "    \"multilingual\": [\n",
    "        \"./data/test/spanish1.wav\",\n",
    "        \"./data/test/french1.wav\",\n",
    "        \"./data/test/hindi1.wav\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n=== Loading Reference Texts ===\")\n",
    "# Load reference texts (if available)\n",
    "REFERENCE_TEXTS = {}\n",
    "try:\n",
    "    ref_path = Path(\"./data/test/references.txt\")\n",
    "    if ref_path.exists():\n",
    "        print(f\"Found references file at: {ref_path.absolute()}\")\n",
    "        # Open with utf-8 and replace invalid chars to avoid mojibake issues\n",
    "        with open(ref_path, encoding='utf-8', errors='replace') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if '\\t' in line:  # expect tab-separated\n",
    "                    fname, text = line.split('\\t', 1)\n",
    "                    REFERENCE_TEXTS[fname.strip()] = text.strip()\n",
    "                    print(f\"Loaded reference for {fname}:\")\n",
    "                    print(f\"Text: \\\"{text.strip()}\\\"\")\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line}\")\n",
    "        \n",
    "        # Verify all test files have references\n",
    "        print(\"\\nChecking reference coverage:\")\n",
    "        for lang, files in TEST_FILES.items():\n",
    "            for fpath in files:\n",
    "                fname = Path(fpath).name\n",
    "                if fname in REFERENCE_TEXTS:\n",
    "                    print(f\"{fname} has reference text\")\n",
    "                else:\n",
    "                    print(f\"Missing reference for {fname}\")\n",
    "    else:\n",
    "        print(\"No references.txt found, WER will use placeholder text\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading references: {str(e)}\")\n",
    "\n",
    "def get_reference_text(file_path):\n",
    "    \"\"\"Get reference text for a file, or return a notice if missing\"\"\"\n",
    "    base_name = Path(file_path).name\n",
    "    text = REFERENCE_TEXTS.get(base_name, \"Reference text not available\")\n",
    "    if text == \"Reference text not available\":\n",
    "        print(f\"No reference text found for {base_name}\")\n",
    "    return text\n",
    "\n",
    "# Use jiwer transforms to normalize both reference and hypothesis consistently\n",
    "from jiwer import wer, Compose, ToLowerCase, RemovePunctuation, RemoveMultipleSpaces, Strip\n",
    "\n",
    "# define transform\n",
    "TRANSFORM_FOR_WER = Compose([\n",
    "    ToLowerCase(),\n",
    "    RemovePunctuation(),\n",
    "    RemoveMultipleSpaces(),\n",
    "    Strip()\n",
    "])\n",
    "\n",
    "def evaluate_model(model_wrapper, audio, sr, reference_text):\n",
    "    \"\"\"Evaluate model and compute WER\"\"\"\n",
    "    start_time = time.time()\n",
    "    mem_start = psutil.Process().memory_info().rss\n",
    "\n",
    "    try:\n",
    "        transcription = model_wrapper.transcribe(audio, sr)\n",
    "        process_time = time.time() - start_time\n",
    "        mem_used = (psutil.Process().memory_info().rss - mem_start) / 1024 / 1024\n",
    "\n",
    "        if reference_text and reference_text != \"Reference text not available\":\n",
    "            ref_transformed = TRANSFORM_FOR_WER(reference_text)\n",
    "            hyp_transformed = TRANSFORM_FOR_WER(transcription)\n",
    "            error_rate = wer(ref_transformed, hyp_transformed)\n",
    "\n",
    "            print(f\"\\nReference: \\\"{reference_text}\\\"\")\n",
    "            print(f\"Generated: \\\"{transcription}\\\"\")\n",
    "            print(f\"Computed WER: {error_rate:.3f}\")\n",
    "            print(f\"WER Rating: {'Excellent' if error_rate <= 0.1 else 'Good' if error_rate <= 0.3 else 'Fair' if error_rate <= 0.5 else 'Poor'}\")\n",
    "        else:\n",
    "            error_rate = float('nan')\n",
    "            print(\"No reference text available for WER calculation\")\n",
    "\n",
    "        return {\n",
    "            \"wer\": error_rate,\n",
    "            \"time\": process_time,\n",
    "            \"memory\": mem_used,\n",
    "            \"transcription\": transcription,\n",
    "            \"reference\": reference_text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# verify test files exist\n",
    "print(\"\\nChecking test files...\")\n",
    "for lang, files in TEST_FILES.items():\n",
    "    for fpath in files:\n",
    "        if Path(fpath).exists():\n",
    "            print(f\"Found {fpath}\")\n",
    "        else:\n",
    "            print(f\"Missing {fpath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb102451",
   "metadata": {},
   "source": [
    "## Run Model Comparison\n",
    "\n",
    "Now let's compare the models on:\n",
    "1. Short audio clips (< 30s)\n",
    "2. Different languages\n",
    "3. Different speech patterns (fast/slow, accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchcodec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, config in MODELS.items():\n",
    "    print(f\"\\nEvaluating {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        model = ModelWrapper(config).load()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    results[model_name] = []\n",
    "    processed_files = set()  # avoiding duplicates\n",
    "\n",
    "    for lang, files in TEST_FILES.items():\n",
    "        for file_path in files:\n",
    "            if file_path in processed_files:\n",
    "                continue\n",
    "            processed_files.add(file_path)\n",
    "\n",
    "            try:\n",
    "                # Use our improved audio loading function\n",
    "                audio, sr = load_test_audio(file_path)\n",
    "                if audio is None:\n",
    "                    print(f\"Skipping {file_path}, audio not loaded\")\n",
    "                    continue\n",
    "\n",
    "                reference_text = get_reference_text(file_path)\n",
    "                print(f\"\\nProcessing {file_path}\")\n",
    "\n",
    "                result = evaluate_model(model, audio, sr, reference_text)\n",
    "                if not result:\n",
    "                    continue\n",
    "\n",
    "                # ensuring numeric fields\n",
    "                result[\"memory\"] = max(result.get(\"memory\", 0), 0)\n",
    "                result[\"wer\"] = result.get(\"wer\", np.nan)\n",
    "\n",
    "                result[\"file\"] = file_path\n",
    "                result[\"language\"] = lang\n",
    "                results[model_name].append(result)\n",
    "\n",
    "                print(f\"Time: {result['time']:.2f}s\")\n",
    "                print(f\"Memory: {result['memory']:.1f}MB\")\n",
    "                if not np.isnan(result[\"wer\"]):\n",
    "                    print(f\"WER: {result['wer']:.3f}\")\n",
    "                print(f\"Output: {result['transcription'][:100]}...\")\n",
    "                if reference_text != \"Reference text not available\":\n",
    "                    print(f\"Expected: {reference_text[:100]}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    print(f\"\\nUnloading {model_name}...\")\n",
    "    try:\n",
    "        model.unload()\n",
    "        print(f\"Unloaded {model_name} and freed memory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error unloading {model_name}: {e}\")\n",
    "\n",
    "\n",
    "# Convert results to DataFrame safely\n",
    "df_results = [\n",
    "    {\n",
    "        \"model\": model_name,\n",
    "        \"language\": r.get(\"language\", \"unknown\"),\n",
    "        \"wer\": r.get(\"wer\", np.nan),\n",
    "        \"time\": r.get(\"time\", np.nan),\n",
    "        \"memory\": r.get(\"memory\", np.nan),\n",
    "        \"file\": r.get(\"file\", \"unknown\")\n",
    "    }\n",
    "    for model_name, model_results in results.items()\n",
    "    for r in model_results\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(df_results)\n",
    "\n",
    "print(\"\\nResults DataFrame Preview\")\n",
    "print(df.head())\n",
    "\n",
    "# Handle missing or empty dataframe\n",
    "if df.empty:\n",
    "    print(\"No results to summarize — check if evaluation produced any output.\")\n",
    "else:\n",
    "    # Print summary\n",
    "    print(\"\\nResults Summary\")\n",
    "    summary = df.groupby(\"model\").agg({\n",
    "        \"wer\": [\"mean\", \"std\"],\n",
    "        \"time\": [\"mean\", \"std\"],\n",
    "        \"memory\": [\"mean\", \"std\"]\n",
    "    }).round(3)\n",
    "\n",
    "    print(\"\\nMetrics by model (mean ± std):\")\n",
    "    for model in summary.index:\n",
    "        wer_mean = summary.loc[model, (\"wer\", \"mean\")]\n",
    "        wer_std = summary.loc[model, (\"wer\", \"std\")]\n",
    "        time_mean = summary.loc[model, (\"time\", \"mean\")]\n",
    "        time_std = summary.loc[model, (\"time\", \"std\")]\n",
    "        mem_mean = summary.loc[model, (\"memory\", \"mean\")]\n",
    "        mem_std = summary.loc[model, (\"memory\", \"std\")]\n",
    "\n",
    "        print(f\"\\n{model}:\")\n",
    "        if not np.isnan(wer_mean):\n",
    "            print(f\"  • WER: {wer_mean:.3f} ± {wer_std:.3f}\")\n",
    "        print(f\"  • Time: {time_mean:.2f}s ± {time_std:.2f}s\")\n",
    "        print(f\"  • Memory: {mem_mean:.1f}MB ± {mem_std:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# First, verify we have data to plot\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDataFrame Head:\")\n",
    "print(df.head())\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(\"Speech Recognition Model Comparison\", fontsize=14, y=1.02)\n",
    "\n",
    "# WER by model\n",
    "if not df[\"wer\"].isna().all():\n",
    "    sns.boxplot(x=\"model\", y=\"wer\", data=df, ax=axes[0,0])\n",
    "    axes[0,0].set_title(\"Word Error Rate by Model\")\n",
    "    axes[0,0].set_ylabel(\"WER\")\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    print(\"No WER values available for plotting\")\n",
    "    axes[0,0].remove()\n",
    "\n",
    "# Processing time by model\n",
    "sns.boxplot(x=\"model\", y=\"time\", data=df, ax=axes[0,1])\n",
    "axes[0,1].set_title(\"Processing Time by Model\")\n",
    "axes[0,1].set_ylabel(\"Time (seconds)\")\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Memory usage by model\n",
    "sns.boxplot(x=\"model\", y=\"memory\", data=df, ax=axes[1,0])\n",
    "axes[1,0].set_title(\"Memory Usage by Model\")\n",
    "axes[1,0].set_ylabel(\"Memory (MB)\")\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# WER by language\n",
    "if not df[\"wer\"].isna().all():\n",
    "    sns.boxplot(x=\"language\", y=\"wer\", data=df, ax=axes[1,1])\n",
    "    axes[1,1].set_title(\"WER by Language\")\n",
    "    axes[1,1].set_ylabel(\"WER\")\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[1,1].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nDetailed Statistics\")\n",
    "stats = df.groupby([\"model\", \"language\"]).agg({\n",
    "    \"wer\": [\"mean\", \"std\", \"count\"],\n",
    "    \"time\": [\"mean\", \"std\"],\n",
    "    \"memory\": [\"mean\", \"std\"]\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nDetailed results by model and language:\")\n",
    "for (model, lang), row in stats.iterrows():\n",
    "    print(f\"\\n{model} - {lang}:\")\n",
    "    if not np.isnan(row[(\"wer\", \"mean\")]):\n",
    "        print(f\"  • WER: {row[('wer', 'mean')]:.3f} ± {row[('wer', 'std')]:.3f} (n={int(row[('wer', 'count')])})\")\n",
    "    print(f\"  • Time: {row[('time', 'mean')]:.2f}s ± {row[('time', 'std')]:.2f}s\")\n",
    "    print(f\"  • Memory: {row[('memory', 'mean')]:.1f}MB ± {row[('memory', 'std')]:.1f}MB\")\n",
    "\n",
    "# Save results with verification\n",
    "results_file = Path(\"./data/test/results.csv\")\n",
    "try:\n",
    "    # Create directory if it doesn't exist\n",
    "    results_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save the data\n",
    "    print(f\"\\nSaving results to {results_file.absolute()}\")\n",
    "    df.to_csv(results_file, index=False)\n",
    "    \n",
    "    # Verify the save by reading it back\n",
    "    df_verify = pd.read_csv(results_file)\n",
    "    if len(df_verify) == len(df):\n",
    "        print(f\"Successfully saved {len(df)} rows of data\")\n",
    "        print(f\"Columns saved: {', '.join(df_verify.columns)}\")\n",
    "    else:\n",
    "        print(f\"Data verification failed: Saved {len(df_verify)} rows but expected {len(df)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {str(e)}\")\n",
    "    print(f\"Current working directory: {Path.cwd()}\")\n",
    "    print(f\"Target save path: {results_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load saved results\n",
    "df = pd.read_csv(\"./data/test/results.csv\")\n",
    "\n",
    "# Check if we have WER values\n",
    "if df['wer'].isnull().all():\n",
    "    print(\"⚠️ No WER values found. Make sure reference texts are available for comparison.\")\n",
    "else:\n",
    "    # pivot table for WER\n",
    "    wer_table = df.pivot_table(\n",
    "        index=\"language\",\n",
    "        columns=\"model\",\n",
    "        values=\"wer\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).round(3)\n",
    "\n",
    "    print(\"=== WER Table ===\")\n",
    "    print(wer_table)\n",
    "    print(\"\\nWER Score Guide:\")\n",
    "    print(\"0.0-0.1:   Excellent (near human-level)\")\n",
    "    print(\"0.1-0.3:   Good (usable for most purposes)\")\n",
    "    print(\"0.3-0.5:   Fair (may need manual correction)\")\n",
    "    print(\">0.5:      Poor (significant errors)\")\n",
    "\n",
    "# pivot table for processing time\n",
    "time_table = df.pivot_table(\n",
    "    index=\"language\",\n",
    "    columns=\"model\",\n",
    "    values=\"time\",\n",
    "    aggfunc=\"mean\"\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nProcessing Time Table (s)\")\n",
    "print(time_table)\n",
    "\n",
    "# pivot table for memory\n",
    "memory_table = df.pivot_table(\n",
    "    index=\"language\",\n",
    "    columns=\"model\",\n",
    "    values=\"memory\",\n",
    "    aggfunc=\"mean\"\n",
    ").round(1)\n",
    "\n",
    "print(\"\\nMemory Usage Table (MB)\")\n",
    "print(memory_table)\n",
    "\n",
    "# Add summary statistics with WER quality indicators\n",
    "print(\"\\nSummary by Model\")\n",
    "model_stats = df.groupby('model').agg({\n",
    "    'wer': lambda x: f\"{x.mean():.3f} ({'Excellent' if x.mean() <= 0.1 else 'Good' if x.mean() <= 0.3 else 'Fair' if x.mean() <= 0.5 else 'Poor'})\",\n",
    "    'time': lambda x: f\"{x.mean():.2f}s\",\n",
    "    'memory': lambda x: f\"{x.mean():.1f}MB\"\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nModel Performance (WER | Processing Time | Memory):\")\n",
    "for model in model_stats.index:\n",
    "    wer_stat = model_stats.loc[model, 'wer']\n",
    "    time_stat = model_stats.loc[model, 'time']\n",
    "    mem_stat = model_stats.loc[model, 'memory']\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"WER: {wer_stat}\")\n",
    "    print(f\"Time: {time_stat}\")\n",
    "    print(f\"Memory: {mem_stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75d6db",
   "metadata": {},
   "source": [
    "# Understanding WER (Word Error Rate)\n",
    "\n",
    "WER measures the minimum number of edits needed to change the transcribed text into the reference text, divided by the number of words in the reference.\n",
    "\n",
    "WER = (Substitutions + Deletions + Insertions) / Number of Reference Words\n",
    "\n",
    "- **WER = 0.0**: Perfect match (best possible score)\n",
    "- **WER = 0.2**: 20% error rate (good for conversational speech)\n",
    "- **WER = 0.5**: 50% error rate (poor performance)\n",
    "- **WER > 1.0**: Very poor performance (more errors than reference words)\n",
    "\n",
    "Lower WER is always better. State-of-the-art models typically achieve:\n",
    "- English: 0.02 - 0.15 (2-15% WER)\n",
    "- Other languages: 0.05 - 0.30 (5-30% WER)\n",
    "- Noisy/accented speech: Up to 0.50 (50% WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test WER calculation with sample files\n",
    "print(\"Testing WER Calculation\")\n",
    "\n",
    "# Test with a single file first\n",
    "test_file = \"./data/test/eng1.wav\"\n",
    "audio, sr = load_test_audio(test_file)\n",
    "if audio is not None:\n",
    "    reference = get_reference_text(test_file)\n",
    "    result = evaluate_model(ModelWrapper(MODELS['whisper-small']).load(), audio, sr, reference)\n",
    "    print(\"\\nDetailed WER Analysis:\")\n",
    "    if result and not np.isnan(result['wer']):\n",
    "        print(f\"Final WER: {result['wer']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d651f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# for model_name, config in MODELS.items():\n",
    "#     wrapper = ModelWrapper(config).load()\n",
    "#     for lang, files in TEST_FILES.items():\n",
    "#         for file_path in files:\n",
    "#             audio, sr = load_test_audio(file_path)\n",
    "#             if audio is None:\n",
    "#                 continue\n",
    "#             reference = get_reference_text(file_path)\n",
    "#             metrics = evaluate_model(wrapper, audio, sr, reference)\n",
    "#             if metrics:\n",
    "#                 metrics.update({\n",
    "#                     \"model\": model_name,\n",
    "#                     \"language\": lang,\n",
    "#                     \"file\": Path(file_path).name\n",
    "#                 })\n",
    "#                 results.append(metrics)\n",
    "#     wrapper.unload()\n",
    "\n",
    "# df_results = pd.DataFrame(results)\n",
    "# df_results.to_csv(\"results_summary.csv\", index=False)\n",
    "# df_results.groupby(\"model\")[[\"wer\", \"time\", \"memory\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b842b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlstateofartenv",
   "language": "python",
   "name": "mlstateofartenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
